{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "316a3adc-c895-4b07-8bab-f5585005d2d3",
   "metadata": {},
   "source": [
    "# カチャカ_ライントレース\n",
    "2023国際ロボット展で展示したX7とカチャカの搬送デモで使用したコードです。  \n",
    "カチャカの前方カメラ画像を用いてライントレースをします。  \n",
    "詳細はアールティ移動型ロボットブログの「ROS 2でカチャカを動かしてみた」の連載を御覧ください。  \n",
    "[https://rt-net.jp/mobility/archives/24768](https://rt-net.jp/mobility/archives/24768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7cf7ce-1fe1-46e8-b849-38da9800a6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from cv2 import aruco\n",
    "import kachaka_api\n",
    "import numpy as np\n",
    "import time\n",
    "from IPython.display import Image, clear_output, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eafb9d8-c5b2-462c-8f9d-3835fa342d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_info = kachaka_api.KachakaApiClient()\n",
    "\n",
    "\n",
    "dictionary = aruco.getPredefinedDictionary(aruco.DICT_6X6_50)\n",
    "parameters = aruco.DetectorParameters()\n",
    "\n",
    "camera_info = client_info.get_front_camera_ros_camera_info()\n",
    "\n",
    "mtx = np.array(camera_info.K, dtype=float).reshape(3, 3)\n",
    "dist = np.array(camera_info.D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7810c6b0-8d65-4ba3-8465-ceeb8ad573d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_line(cv_image):\n",
    "    hsv = cv2.cvtColor(cv_image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    lower_yellow = np.array([20, 80, 10])  \n",
    "    upper_yellow = np.array([40, 255, 255])  \n",
    "\n",
    "    lower_white = np.array([0, 0, 200], dtype=np.uint8)  \n",
    "    upper_white = np.array([180, 25, 255], dtype=np.uint8)\n",
    "\n",
    "    lower_blue = np.array([90, 50, 50])\n",
    "    upper_blue = np.array([130, 255, 255])\n",
    "\n",
    "    lower_pink = np.array([140, 50, 50]) \n",
    "    upper_pink = np.array([170, 255, 255])  \n",
    "\n",
    "    lower_green = np.array([30, 64, 40])  \n",
    "    upper_green = np.array([90, 255, 255])\n",
    "    \n",
    "    mask = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
    "\n",
    "    \n",
    "    res = cv2.bitwise_and(cv_image, cv_image, mask=mask)\n",
    "    h, w = cv_image.shape[:2]\n",
    "    \n",
    "    range = (h//4)*3\n",
    "    mask[0:range, 0:w] = 0\n",
    "    mask[range+30:h, 0:w] = 0\n",
    "    \n",
    "    return mask, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11501be0-bf41-43a2-98aa-bd0e0e93d913",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = kachaka_api.aio.KachakaApiClient()\n",
    "STARTFLAG = False\n",
    "marker_length = 0.04\n",
    "stop_distance = 0.3\n",
    "wait_timer = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb403f0a-34c4-4d69-9aac-44646b419d24",
   "metadata": {},
   "source": [
    "以下実行後、スマートフォンなどで https://pf-robotics.github.io/textcode/ にアクセスし、QRコードをカチャカの前カメラの前に近付けてコマンドを指令して下さい。  \n",
    "コマンド一覧\n",
    "- home：充電ドックに戻る\n",
    "- dock：シェルフにドッキング\n",
    "- unlock：シェルフを解除\n",
    "- start：ライントレース開始\n",
    "- stop：ライントレース停止"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e4e1a0-f7d9-431f-bcf4-59cb3c604860",
   "metadata": {},
   "outputs": [],
   "source": [
    "qcd = cv2.QRCodeDetector()\n",
    "await client.speak(\"起動しました\")\n",
    "async for image in client.front_camera_ros_compressed_image.stream():\n",
    "    cv_image = cv2.imdecode(np.frombuffer(image.data, dtype=np.uint8), flags=1)\n",
    "    decoded_info, corners, _ = qcd.detectAndDecode(cv_image)\n",
    "    \n",
    "    if decoded_info != \"\":\n",
    "        cv_image = cv2.putText(\n",
    "            cv_image,\n",
    "            decoded_info,\n",
    "            corners[0][0].astype(int),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            1,\n",
    "            (0, 0, 255),\n",
    "            2,\n",
    "            cv2.LINE_AA,\n",
    "        )\n",
    "\n",
    "        if decoded_info == \"home\":\n",
    "            line_tracer == False\n",
    "            await client.return_home(cancel_all=True,tts_on_success=\"ホームに戻りました\")\n",
    "        if decoded_info == \"dock\":\n",
    "            await client.dock_shelf(cancel_all=True)\n",
    "        if decoded_info == \"unlock\":\n",
    "            await client.undock_shelf(cancel_all=True)\n",
    "        if decoded_info == \"start\":\n",
    "            STARTFLAG = True\n",
    "            await client.speak(\"ライントレースを開始します\")\n",
    "        if decoded_info == \"stop\":\n",
    "            STARTFLAG = False\n",
    "            await client.speak(\"待機します\")\n",
    "\n",
    "    if STARTFLAG == True:\n",
    "        h, w = cv_image.shape[:2]\n",
    "        corners_ar, ids, rejectedImgPoints = aruco.detectMarkers(cv_image, dictionary)\n",
    "    \n",
    "        if corners_ar:\n",
    "            for i in range(len(ids)):\n",
    "                rvec, tvec, _ = cv2.aruco.estimatePoseSingleMarkers(corners_ar, marker_length, mtx, dist)\n",
    "                x = tvec[0][0][0]\n",
    "                z = tvec[0][0][2]\n",
    "                if  z  < stop_distance:\n",
    "                    time.sleep(wait_timer)\n",
    "                    pose = await client.get_robot_pose()\n",
    "                    await client.move_to_pose(pose.x, pose.y, pose.theta - np.pi)\n",
    "                    continue\n",
    "    \n",
    "        mask, res = detect_line(cv_image)\n",
    "        \n",
    "        M = cv2.moments(mask)\n",
    "        if M['m00'] > 0 :\t\n",
    "            cx,cy = int(M['m10']/M['m00']), int(M['m01']/M['m00'])\n",
    "            \t\n",
    "            cv2.circle(cv_image, (cx, cy), 20, (0, 0, 255), -1)\n",
    "            diff = cx - w//2\t\n",
    "            angle = -float(diff)/1500\n",
    "            await client.set_robot_velocity(linear=0.10, angular=angle)\n",
    "            \n",
    "    _, ret = cv2.imencode(\n",
    "        \".jpg\",\n",
    "        cv2.resize(cv_image, (int(cv_image.shape[1] / 2), int(cv_image.shape[0] / 2))),\n",
    "    )\n",
    "    clear_output(wait=True)\n",
    "    display(Image(data=ret, format=\"jpeg\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
